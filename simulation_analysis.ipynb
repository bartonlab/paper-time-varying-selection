{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e25a74",
   "metadata": {},
   "source": [
    "# <font color = red> Simulation Analyze\n",
    "This notebook records the parameters for Wright-Fisher simulations used to generate our test data sets, as well as commands for running infernce algorithms on the test data and compiling the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf1a29",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- ### [Libraries and variables](#lib)\n",
    "- ### Data analyze\n",
    "    - [Generation of test data through Wright-Fisher simulations](#sim)\n",
    "    - [Collect multiple simulations](#collect)\n",
    "    - [Finite sample data](#nsdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d18bec",
   "metadata": {},
   "source": [
    "### <a id='lib'></a> Libraries and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "235449e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was prepared using:\n",
      "python version 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:26:08) [Clang 14.0.6 ]\n",
      "numpy version 1.24.2\n",
      "pandas version 1.5.3\n",
      "matplotlib version 3.7.1\n"
     ]
    }
   ],
   "source": [
    "print('This notebook was prepared using:')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "print('python version %s' % sys.version)\n",
    "\n",
    "import numpy as np\n",
    "print('numpy version %s' % np.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "print('pandas version %s' % pd.__version__)\n",
    "\n",
    "import math\n",
    "from math import isnan\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "print('matplotlib version %s' % matplotlib.__version__)\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import scipy as sp\n",
    "import random\n",
    "\n",
    "from scipy import integrate\n",
    "import scipy.interpolate as sp_interpolate\n",
    "import statistics\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import time as time_module\n",
    "\n",
    "import json\n",
    "from importlib import reload\n",
    "\n",
    "import simulation as sim\n",
    "import importlib\n",
    "\n",
    "# GitHub directories\n",
    "HIV_DIR = 'data/HIV'\n",
    "MPL_DIR = 'src/MPL'\n",
    "SIM_DIR = 'data/simulation'\n",
    "FIG_DIR = 'figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd137999-898e-4a79-9250-6a3a3eabec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameter\n",
    "importlib.reload(sim)\n",
    "\n",
    "generations = 1000\n",
    "fi_1 = np.zeros(generations+1)\n",
    "fi_2 = np.zeros(generations+1)\n",
    "\n",
    "for t in range(len(fi_1)):\n",
    "    fi_1[t] = np.sin(t*2*np.pi/generations)*0.04\n",
    "    fi_2[t] = np.cos(t*2*np.pi/generations)*0.04\n",
    "    \n",
    "pdata = {  \n",
    "    'NUC':           ['A', 'T'],      # all possible alleles\n",
    "    'dir':           'simple-new',    # directory of this simulation\n",
    "    'xfile':         '0',             # output file name\n",
    "    'output_dir':    'output',        # directory of reference result\n",
    "    'seq_length':    10,              # sequence length\n",
    "    'pop_size':      1000,            # population size\n",
    "    'generations':   generations,     # number of total generations\n",
    "    'mut_rate':      1e-3,            # mutation rate\n",
    "    'rec_rate':      1e-3,            # recombination rate\n",
    "    'inital_state':  4,               # number of initial sub-population\n",
    "    'bene':          [0,1],           # constant beneficial mutations sites\n",
    "    'dele':          [4,5],           # constant deleterious mutations sites\n",
    "    'p_1':           [6,7],           # time-varying mutations sites (sin)\n",
    "    'p_2':           [8,9],           # time-varying mutations sites (cos)\n",
    "    's_ben':         0.03,            # selection coefficient of beneficial mutations\n",
    "    's_del':         -0.03,           # selection coefficient of deleterious mutations\n",
    "    'fi_1':          fi_1,            # time-varying selection coefficient for individual site (sin)\n",
    "    'fi_2':          fi_2,            # time-varying selection coefficient for individual site (cos)\n",
    "    'gamma_s':       1,               # regularization - selection coefficients - constant part\n",
    "    'gamma_2c':      100000,          # regularization - the time derivative of the selection coefficients\n",
    "    'gamma_2tv':     200,             # regularization - the time derivative of the selection coefficients\n",
    "    'theta':         0.5,             # magnification of extended time at the ends\n",
    "    'beta':          4,               # magnification of extended gamma_2 at the ends\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23826288-5967-40ea-b6b0-b61335b2913d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done 100 simulations\n"
     ]
    }
   ],
   "source": [
    "reload(sim)\n",
    "\n",
    "n_sim   = 100\n",
    "\n",
    "# simulation\n",
    "for k in range(n_sim):\n",
    "    pdata['xfile']        = str(k)\n",
    "    sim.simulate_simple(**pdata)\n",
    "\n",
    "print('we have done %d simulations'%n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42fc732c-e0a2-4c8c-9d79-939f5f952c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done inference for 100 simulations \n"
     ]
    }
   ],
   "source": [
    "reload(sim)\n",
    "\n",
    "for n in range(n_sim):\n",
    "    pdata['xfile'] = str(n)\n",
    "    sim.infer_simple(**pdata)\n",
    "\n",
    "print('we have done inference for %d simulations '%n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "864b49d8-bf7a-4768-a6a2-6dbc229fd8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done inference for 100 simulations （assuming all mutations are time-varying）\n"
     ]
    }
   ],
   "source": [
    "'''Consider all mutations are time-varying'''\n",
    "reload(sim)\n",
    "\n",
    "pdata['output_dir'] = 'output-tv'\n",
    "pdata['p_1'] = [0, 1, 2, 3, 4]\n",
    "pdata['p_2'] = [5, 6, 7, 8, 9]\n",
    "\n",
    "for n in range(n_sim):\n",
    "    pdata['xfile'] = str(n)\n",
    "    sim.infer_simple(**pdata)\n",
    "\n",
    "print('Done inference for %d simulations （assuming all mutations are time-varying）'%n_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35f4cd2",
   "metadata": {},
   "source": [
    "<!-- <a id=''></a> -->\n",
    "### Generation of test data through Wright-Fisher simulations without binary trait term\n",
    "The fitness model work like this:\n",
    "$f_a = 1 + \\sum_i^L s_i g_i^a$\n",
    "\n",
    "This simulation begins with 4 random initial type, which only has 2 alleles (wild type and mutant type).\n",
    "\n",
    "Wright-Fisher simulations are performed using simulation.py. The output of these simulations is saved for processing. \n",
    "\n",
    "In this part, we use python code to run mpl.\n",
    "\n",
    "Benefial [0,1], neutral [2,3], delerious[4,5], time varying site (sin(t))[6,7], time varying site (sin(t))[8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f41ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameter\n",
    "importlib.reload(sim)\n",
    "\n",
    "generations = 1000\n",
    "fi_1 = np.zeros(generations+1)\n",
    "fi_2 = np.zeros(generations+1)\n",
    "\n",
    "for t in range(len(fi_1)):\n",
    "    fi_1[t] = np.sin(t*2*np.pi/generations)*0.04\n",
    "    fi_2[t] = np.cos(t*2*np.pi/generations)*0.04\n",
    "    \n",
    "pdata = {  \n",
    "    'NUC':           ['A', 'T'],      # all possible alleles\n",
    "    'dir':           'simple',        # directory of this simulation\n",
    "    'xfile':         '0',             # output file name\n",
    "    'output_dir':    'output',        # directory of reference result\n",
    "    'seq_length':    10,              # sequence length\n",
    "    'pop_size':      1000,            # population size\n",
    "    'generations':   generations,     # number of total generations\n",
    "    'mut_rate':      1e-3,            # mutation rate\n",
    "    'rec_rate':      1e-3,            # recombination rate\n",
    "    'inital_state':  4,               # number of initial sub-population\n",
    "    'bene':          [0,1],           # constant beneficial mutations sites\n",
    "    'dele':          [4,5],           # constant deleterious mutations sites\n",
    "    'p_1':           [6,7],           # time-varying mutations sites (sin)\n",
    "    'p_2':           [8,9],           # time-varying mutations sites (cos)\n",
    "    's_ben':         0.02,            # selection coefficient of beneficial mutations\n",
    "    's_del':         -0.02,           # selection coefficient of deleterious mutations\n",
    "    'fi_1':          fi_1,            # time-varying selection coefficient for individual site (sin)\n",
    "    'fi_2':          fi_2,            # time-varying selection coefficient for individual site (cos)\n",
    "    'gamma_s':       1,               # regularization - selection coefficients - constant part\n",
    "    'gamma_2c':      100000,          # regularization - the time derivative of the selection coefficients\n",
    "    'gamma_2tv':     200,             # regularization - the time derivative of the selection coefficients\n",
    "    'theta':         0.5,             # magnification of extended time at the ends\n",
    "    'beta':          4,               # magnification of extended gamma_2 at the ends\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3da6ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done 100 simulations\n"
     ]
    }
   ],
   "source": [
    "reload(sim)\n",
    "\n",
    "n_sim   = 100\n",
    "\n",
    "# simulation\n",
    "for k in range(n_sim):\n",
    "    pdata['xfile']        = str(k)\n",
    "#     sim.simulate_simple(**pdata)\n",
    "\n",
    "print('we have done %d simulations'%n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3003e2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done inference for 100 simulations \n"
     ]
    }
   ],
   "source": [
    "reload(sim)\n",
    "\n",
    "for n in range(n_sim):\n",
    "    pdata['xfile'] = str(n)\n",
    "    sim.infer_simple(**pdata)\n",
    "\n",
    "print('we have done inference for %d simulations '%n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "815eeb78-ffb4-4691-9a12-6c2381774aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done inference for 100 simulations （assuming all mutations are time-varying）\n"
     ]
    }
   ],
   "source": [
    "'''Consider all mutations are time-varying'''\n",
    "reload(sim)\n",
    "\n",
    "pdata['output_dir'] = 'output-tv'\n",
    "pdata['p_1'] = [0, 1, 2, 3, 4]\n",
    "pdata['p_2'] = [5, 6, 7, 8, 9]\n",
    "\n",
    "for n in range(n_sim):\n",
    "    pdata['xfile'] = str(n)\n",
    "    sim.infer_simple(**pdata)\n",
    "\n",
    "print('Done inference for %d simulations （assuming all mutations are time-varying）'%n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d279a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collect all coefficients for 100 simulations\n"
     ]
    }
   ],
   "source": [
    "simple_dir = pdata['dir']\n",
    "output_dir = pdata['output_dir']\n",
    "beta       = pdata['beta']\n",
    "\n",
    "const_num = 6\n",
    "f = open('%s/%s/mpl_collected_%s.csv'%(SIM_DIR,simple_dir,beta),'w')\n",
    "f.write('trajectory,ns,delta_t')\n",
    "for i in range(const_num):\n",
    "    f.write(',sc_%d'%i)\n",
    "f.write('\\n')\n",
    "\n",
    "for k in range(n_sim):\n",
    "    name = str(k)\n",
    "    data_full   = np.load('%s/%s/%s/c_%s.npz'%(SIM_DIR,simple_dir,output_dir,name), allow_pickle=\"True\")\n",
    "    sc_full     = data_full['selection']\n",
    "    TimeVaryingSC = [np.average(sc_full[i]) for i in range(const_num)]\n",
    "    f.write('%d,1000,1'%k)\n",
    "    for i in range(const_num):\n",
    "        f.write(',%f'%TimeVaryingSC[i])\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "print('collect all coefficients for %d simulations'%(n_sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4283bcb8",
   "metadata": {},
   "source": [
    "Use different $\\gamma^{\\prime}$ to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1d6ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done inference for 100 simulations in both cases\n"
     ]
    }
   ],
   "source": [
    "reload(sim)\n",
    "\n",
    "for n in range(n_sim):\n",
    "    pdata['xfile'] = str(n)\n",
    "    \n",
    "    '''Smaller gammma^{prime} at the ends'''\n",
    "    pdata['output_dir'] = 'output_0.25'\n",
    "    pdata['beta'] = 0.25\n",
    "    sim.infer_simple(**pdata)\n",
    "\n",
    "    '''Concant gammma^{prime} '''\n",
    "    pdata['output_dir'] = 'output_1'\n",
    "    pdata['beta'] = 1\n",
    "    sim.infer_simple(**pdata)\n",
    "\n",
    "print('we have done inference for %d simulations in both cases'%n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f67d4a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have collected all coefficientse for 100 simulations for both cases\n"
     ]
    }
   ],
   "source": [
    "reload(sim)\n",
    "\n",
    "betas = [0.25, 1]\n",
    "const_num = 6\n",
    "\n",
    "for beta in betas:\n",
    "    # write the constant reference result\n",
    "    f = open('%s/%s/mpl_collected_%s.csv'%(SIM_DIR,simple_dir,beta),'w')\n",
    "    f.write('trajectory,ns,delta_t')\n",
    "    for i in range(const_num):\n",
    "        f.write(',sc_%d'%i)\n",
    "    f.write('\\n')\n",
    "    \n",
    "    for k in range(n_sim):\n",
    "        name = str(k)\n",
    "        data_full   = np.load('%s/%s/output_%s/c_%s.npz'%(SIM_DIR,simple_dir,beta,name), allow_pickle=\"True\")\n",
    "        sc_full     = data_full['selection']\n",
    "        TimeVaryingSC = [np.average(sc_full[i]) for i in range(const_num)]\n",
    "        f.write('%d,1000,1'%k)\n",
    "        for i in range(const_num):\n",
    "            f.write(',%f'%TimeVaryingSC[i])\n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "print('we have collected all constant coefficientse for %d simulations for both cases'%n_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924df50a",
   "metadata": {},
   "source": [
    "<a id='sim'></a>\n",
    "### Generation of test data through Wright-Fisher simulations\n",
    "The fitness model work like this:\n",
    "$f_a = 1 + \\sum_i^L s_i g_i^a + \\sum_n^{N_p} s_n g_n^a$\n",
    "\n",
    "This simulation begins with 4 random initial type, which only has 2 alleles (wild type and mutant type).\n",
    "\n",
    "Wright-Fisher simulations are performed using simulation.py. The output of these simulations is saved for processing. \n",
    "\n",
    "In this part, we use python code to run mpl.\n",
    "\n",
    "Benefial [0,1,2,3], delerious[16,17,18,19], trait sites: chosen randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c109fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameter\n",
    "importlib.reload(sim)\n",
    "\n",
    "generations = 1000\n",
    "fn = np.zeros(generations+1)\n",
    "fi = np.zeros(generations+1)\n",
    "\n",
    "for t in range(len(fn)):\n",
    "    fi[t] = 0.04 - 0.08/generations * t\n",
    "    fn[t] = 0.06 - 0.06/generations * t\n",
    "\n",
    "trait_dir = 'trait'\n",
    "pdata = {  \n",
    "    'NUC':           ['A', 'T'],      # all possible alleles\n",
    "    'dir':           trait_dir,       # directory of this simulation\n",
    "    'xfile':         '0',             # output file name\n",
    "    'seq_dir':       'sequences',     # directory of input simulation data\n",
    "    'output_dir':    'output',        # directory of reference result\n",
    "    'seq_length':    20,              # sequence length\n",
    "    'pop_size':      1000,            # population size\n",
    "    'generations':   generations,     # number of total generations\n",
    "    'totalT':        generations,     # generations used to infer\n",
    "    'mut_rate':      1e-3,            # mutation rate\n",
    "    'rec_rate':      1e-3,            # recombination rate\n",
    "    'inital_state':  4,               # number of initial sub-population\n",
    "    'n_ben':         4,               # number of beneficial mutations\n",
    "    'n_del':         4,               # number of deleterious mutations\n",
    "    'bene':          [0,1,2,3],       # constant beneficial mutations sites\n",
    "    'dele':          [16,17,18,19],   # constant deleterious mutations sites\n",
    "    's_ben':         0.02,            # selection coefficient of beneficial mutations\n",
    "    's_del':         -0.02,           # selection coefficient of deleterious mutations\n",
    "    'fi':            fi,              # time-varying selection coefficient for individual site\n",
    "    'fn':            fn,              # time-varying selection coefficient for binary trait\n",
    "    'escape_group':  [[12,15,17]],    # escape sites\n",
    "    'escape_TF':     [[0,0,0]],       # wild type sequences for escape sites\n",
    "    'trait_dis':     [[3,2]],         # distance between trait sites\n",
    "    'p_sites':       [9,10],          # special sites (not escape sites but still time-varying)\n",
    "    'x_thresh':      0.005,           # threshold for single allele frequency\n",
    "    'gamma_s':       1,               # regularization - selection coefficients - constant part\n",
    "    'gamma_2c':      100000,          # regularization - the time derivative of the selection coefficients\n",
    "    'gamma_2tv':     200,              # regularization - the time derivative of the selection coefficients\n",
    "    'theta':         0.5,             # magnification of extended time at the ends\n",
    "    'beta':          4,               # magnification of extended gamma_2 at the ends\n",
    "    'bc_n':          True,            # True: Neumann boundary condition; False: Dirichlet boundary condition\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce191131",
   "metadata": {},
   "source": [
    "Use 3 files to restore the information about trait groups. (\"traitsites\": trait sites , \"traitseq\": TF sequences for trait sites,\"traitdis\":distance between 2 neighboring trait sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b7221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Create the necessary files'\n",
    "reload(sim)\n",
    "\n",
    "n_sim   = 100\n",
    "\n",
    "# # get random escape groups for 100 simulations\n",
    "# escape_groups  = []\n",
    "# special_groups = []\n",
    "# for n in range(n_sim):\n",
    "#     random_numbers   = random.sample(range(20), 3)\n",
    "#     escape_group     = [sorted(random_numbers)]\n",
    "#     escape_groups.append(escape_group)\n",
    "    \n",
    "#     # trait sites \n",
    "#     f = open('%s/%s/traitsite/traitsite-%s.dat'%(SIM_DIR,trait_dir,n), 'w')\n",
    "#     for i in range(len(escape_group)):\n",
    "#         f.write('%s\\n'%'\\t'.join([str(ii) for ii in escape_group[i]]))\n",
    "#     f.close()\n",
    "    \n",
    "#     # distance between 2 trait sites\n",
    "#     f = open('%s/%s/traitdis/traitdis-%s.dat'%(SIM_DIR,trait_dir,n), 'w')\n",
    "#     for i in range(len(escape_group)):\n",
    "#         i_dis = []\n",
    "#         for j in range(len(escape_group[i])-1):\n",
    "#             i_dis.append(int(escape_group[i][j+1]-escape_group[i][j]))\n",
    "#         f.write('%s\\n'%'\\t'.join([str(ii) for ii in i_dis]))\n",
    "#     f.close()\n",
    "    \n",
    "\n",
    "# # trait sequence \n",
    "# f = open('%s/%s/traitseq.dat'%(SIM_DIR,trait_dir), 'w')\n",
    "# for i in range(1):\n",
    "#     f.write('%s\\n'%'\\t'.join([str(0) for j in range(3)]))\n",
    "# f.close()\n",
    "    \n",
    "# # save and load escape group information\n",
    "# with open(\"%s/%s/escape_groups.dat\"%(SIM_DIR,trait_dir), 'w') as file:\n",
    "#     json.dump(escape_groups, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634e8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done 100 times simulations\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sim)\n",
    "\n",
    "with open(\"%s/%s/escape_groups.dat\"%(SIM_DIR,trait_dir), 'r') as file:\n",
    "    escape_groups = json.load(file)\n",
    "    \n",
    "# simulation\n",
    "# for k in range(n_sim):\n",
    "#     pdata['xfile']        = str(k)\n",
    "#     pdata['escape_group'] = escape_groups[k]\n",
    "#     sim.simulate_trait(**pdata)\n",
    "\n",
    "print('we have done %d times simulations'%n_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc98a60",
   "metadata": {},
   "source": [
    "Infer the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "323cabf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done inference for 100 simulations \n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sim)\n",
    "\n",
    "for n in range(n_sim):\n",
    "    pdata['xfile']        = str(n)\n",
    "    sim.infer_trait(**pdata)\n",
    "\n",
    "print('we have done inference for %d simulations '%n_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2a362",
   "metadata": {},
   "source": [
    "#### <a id='collect'></a> Collect the inference results for multiple simulations\n",
    "Create a csv file to store the results of all simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a99e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nB = pdata['n_ben']\n",
    "nD = pdata['n_del']\n",
    "ne = len(pdata['escape_group'])\n",
    "\n",
    "seq_length = pdata['seq_length']\n",
    "p_sites    = [9,10]\n",
    "out_dir    = ''\n",
    "trait_dir = pdata['dir']\n",
    "\n",
    "# Neumann boundary condition\n",
    "f = open('%s/%s/mpl_collected%s.csv'%(SIM_DIR,trait_dir,out_dir),'w')\n",
    "f.write('trajectory,ns,delta_t')\n",
    "for i in range(seq_length):\n",
    "    if i not in p_sites:\n",
    "        f.write(',sc_%d'%i)\n",
    "f.write('\\n')\n",
    "\n",
    "for k in range(100):\n",
    "    name = str(k)\n",
    "    data_full   = np.load('%s/%s/output%s/c_%s.npz'%(SIM_DIR,trait_dir,out_dir,name), allow_pickle=\"True\")\n",
    "    sc_full     = data_full['selection']\n",
    "    TimeVaryingSC = [np.average(sc_full[i]) for i in range(seq_length)]\n",
    "    f.write('%d,1000,1'%k)\n",
    "    for i in range(seq_length):\n",
    "        if i not in p_sites:\n",
    "            f.write(',%f'%TimeVaryingSC[i])\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19bc6da-23fb-4839-a01c-8850bdc84601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d15a8f-b00a-412f-afa0-777a3b39c502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5e8fa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done inference for 100 simulations in both cases\n"
     ]
    }
   ],
   "source": [
    "reload(sim)\n",
    "\n",
    "for n in range(n_sim):\n",
    "    pdata['xfile'] = str(n)\n",
    "    \n",
    "    '''Smaller gammma^{prime} at the ends'''\n",
    "    pdata['output_dir'] = 'output_0.25'\n",
    "    pdata['beta'] = 0.25\n",
    "    sim.infer_trait(**pdata)\n",
    "\n",
    "    '''Constant gammma^{prime} '''\n",
    "    pdata['output_dir'] = 'output_1'\n",
    "    pdata['beta'] = 1\n",
    "    sim.infer_trait(**pdata)\n",
    "\n",
    "print('we have done inference for %d simulations in both cases'%n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bce77f1-6e58-4749-a056-67e01bda5140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done inference for 100 simulations with different gamma^{\\prime}\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sim)\n",
    "'''cut sequence and then infer'''\n",
    "\n",
    "dt = 20\n",
    "observed_time = np.linspace(0, 1000, int(1000/dt)+1)\n",
    "pdata['cut_dir'] = str(dt)\n",
    "pdata['cut_time'] = observed_time\n",
    "pdata['seq_dir'] = 'cut/'+str(dt)+'/sequences'\n",
    "output_dir = 'cut/'+str(dt)+'/output'\n",
    "\n",
    "# pdata['cut_dir']  = 'random'\n",
    "# pdata['cut_time'] = [0, 10, 25, 70, 135, 250, 400, 590, 720, 880, 1000]\n",
    "# pdata['seq_dir']  = 'cut/random/sequences'\n",
    "# output_dir        = 'cut/random/output'\n",
    "\n",
    "for n in range(n_sim):\n",
    "    pdata['xfile']        = str(n)\n",
    "    sim.cut_seq(**pdata)\n",
    "\n",
    "for n in range(n_sim):\n",
    "    pdata['xfile']        = str(n)\n",
    "    \n",
    "    '''Standard gammma^{prime} at the ends'''\n",
    "    pdata['output_dir'] = output_dir\n",
    "    pdata['beta'] = 4\n",
    "    sim.infer_trait(**pdata)\n",
    "\n",
    "    '''Smaller gammma^{prime} at the ends'''\n",
    "    pdata['output_dir'] = output_dir + '_0.25'\n",
    "    pdata['beta'] = 0.25\n",
    "    sim.infer_trait(**pdata)\n",
    "\n",
    "    '''Constant gammma^{prime} '''\n",
    "    pdata['output_dir'] = output_dir + '_1'\n",
    "    pdata['beta'] = 1\n",
    "    sim.infer_trait(**pdata)\n",
    "\n",
    "print('we have done inference for %d simulations with different gamma^{\\prime}'%n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "721f5b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done inference for 100 simulations with different gamma^{\\prime}\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sim)\n",
    "'''cut sequence and then infer'''\n",
    "\n",
    "# dt = 10\n",
    "# observed_time = np.linspace(0, 1000, int(1000/dt)+1)\n",
    "# pdata['cut_dir'] = str(dt)\n",
    "# pdata['cut_time'] = observed_time\n",
    "# pdata['seq_dir'] = 'cut/'+str(dt)+'/sequences'\n",
    "# output_dir = 'cut/'+str(dt)+'/output'\n",
    "\n",
    "pdata['cut_dir']  = 'random'\n",
    "pdata['cut_time'] = [0, 10, 25, 70, 135, 250, 400, 590, 720, 880, 1000]\n",
    "pdata['seq_dir']  = 'cut/random/sequences'\n",
    "output_dir        = 'cut/random/output'\n",
    "\n",
    "# for n in range(n_sim):\n",
    "#     pdata['xfile']        = str(n)\n",
    "#     sim.cut_seq(**pdata)\n",
    "\n",
    "for n in range(n_sim):\n",
    "    pdata['xfile']        = str(n)\n",
    "    \n",
    "    '''Standard gammma^{prime} at the ends'''\n",
    "    pdata['output_dir'] = output_dir\n",
    "    pdata['beta'] = 4\n",
    "    sim.infer_trait(**pdata)\n",
    "\n",
    "    '''Smaller gammma^{prime} at the ends'''\n",
    "    pdata['output_dir'] = output_dir + '_0.25'\n",
    "    pdata['beta'] = 0.25\n",
    "    sim.infer_trait(**pdata)\n",
    "\n",
    "    '''Constant gammma^{prime} '''\n",
    "    pdata['output_dir'] = output_dir + '_1'\n",
    "    pdata['beta'] = 1\n",
    "    sim.infer_trait(**pdata)\n",
    "\n",
    "print('we have done inference for %d simulations with different gamma^{\\prime}'%n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e1db89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0746ed3",
   "metadata": {},
   "source": [
    "#### <a id='nsdt'></a> Finite sample data inference\n",
    "\n",
    "For one simulation, use different n_s and Δt to get the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffc86a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# reload(sim)\n",
    "\n",
    "# ns_vals = [1000, 200, 100, 50, 20, 10]\n",
    "# dt_vals = [   1,   5,  10, 20, 50]\n",
    "# pdata['ns_vals'] = ns_vals\n",
    "# pdata['dt_vals'] = dt_vals\n",
    "\n",
    "# for k in range(n_sim):\n",
    "#     pdata['xfile'] = str(k)\n",
    "#     sim.py2c(**pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dea2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(sim)\n",
    "\n",
    "# pdata['IF_raw'] = True\n",
    "# pdata['xfile']        = str(0)\n",
    "# pdata['p_sites']      = special_groups[0]\n",
    "# sim.infer_binary(**pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "538a4472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdata['IF_raw'] = False\n",
    "# for n in range(n_sim):\n",
    "#     pdata['p_sites']      = special_groups[n]\n",
    "#     for ns in ns_vals:\n",
    "#         for dt in dt_vals:\n",
    "#             if ns*dt>50:\n",
    "#                 pdata['xfile'] = str(n)+'_ns'+str(ns)+'_dt'+str(dt)\n",
    "#                 sim.infer_binary(**pdata)\n",
    "#                 sim.infer_multiple(**pdata)\n",
    "\n",
    "# print('we have done inference for %d simulations with finite sample'%n_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da4d55",
   "metadata": {},
   "source": [
    "collect coefficients for all simulations and write the result into mpl_collected.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b17bf2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # binary python \n",
    "# f = open('%s/mpl_collected_nsdt.csv'%(SIM_DIR),'w')\n",
    "# f.write('trajectory,ns,delta_t')\n",
    "# for i in range(seq_length):\n",
    "#     f.write(',sc_%d'%i)\n",
    "# f.write('\\n')\n",
    "\n",
    "# for k in range(100):\n",
    "#     for ns in ns_vals:\n",
    "#         for dt in dt_vals:\n",
    "#             if ns*dt>50:\n",
    "#                 name = str(k)+'_ns'+str(ns)+'_dt'+str(dt)\n",
    "#                 data_full   = np.load('%s/output/nsdt/c_%s.npz'%(SIM_DIR,name), allow_pickle=\"True\")\n",
    "#                 sc_full     = data_full['selection']\n",
    "#                 TimeVaryingSC = [np.average(sc_full[i]) for i in range(seq_length)]\n",
    "#                 p_sites = special_groups[k]\n",
    "#                 f.write('%d,%d,%d'%(k,ns,dt))\n",
    "#                 for i in range(seq_length):\n",
    "#                     if i not in p_sites:\n",
    "#                         f.write(',%f'%TimeVaryingSC[i])\n",
    "#                     else:\n",
    "#                         f.write(',nan')\n",
    "#                 f.write('\\n')\n",
    "# f.close()\n",
    "\n",
    "# print('collect all coefficients for %d simulations'%(k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3aea77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # multiple python \n",
    "# f = open('%s/mpl_collected_nsdt_multiple.csv'%(SIM_DIR),'w')\n",
    "# f.write('trajectory,ns,delta_t')\n",
    "# for i in range(seq_length):\n",
    "#     f.write(',sc_%d'%i)\n",
    "# f.write('\\n')\n",
    "\n",
    "# for k in range(100):\n",
    "#     for ns in ns_vals:\n",
    "#         for dt in dt_vals:\n",
    "#             if ns*dt>50:\n",
    "#                 name = str(k)+'_ns'+str(ns)+'_dt'+str(dt)\n",
    "#                 data_full   = np.load('%s/output_multiple/nsdt/c_%s.npz'%(SIM_DIR,name), allow_pickle=\"True\")\n",
    "#                 sc_full     = data_full['selection']\n",
    "#                 TimeVaryingSC = [np.average((sc_full[2*i+1]-sc_full[2*i])) for i in range(seq_length)]\n",
    "#                 p_sites = special_groups[k]\n",
    "#                 f.write('%d,%d,%d'%(k,ns,dt))\n",
    "#                 for i in range(seq_length):\n",
    "#                     if i not in p_sites:\n",
    "#                         f.write(',%f'%TimeVaryingSC[i])\n",
    "#                     else:\n",
    "#                         f.write(',nan')\n",
    "#                 f.write('\\n')\n",
    "# f.close()\n",
    "\n",
    "# print('collect all coefficients for %d simulations'%(k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ac0b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn as sk\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# nB = pdata['n_ben']\n",
    "# nD = pdata['n_del']\n",
    "\n",
    "# fB = pdata['s_ben']\n",
    "# fD = pdata['s_del']\n",
    "\n",
    "\n",
    "# true_ben = [1 if i in                        range(nB) else 0 for i in range(seq_length)]\n",
    "# true_del = [1 if i in range(seq_length-nD, seq_length) else 0 for i in range(seq_length)]\n",
    "\n",
    "# coefs = ['sc_%d' % j for j in range(seq_length)]\n",
    "\n",
    "# df              = pd.read_csv('%s/mpl_collected_nsdt.csv'%SIM_DIR, memory_map=True)\n",
    "\n",
    "# # difference between inferred coefficients and true coefficients\n",
    "# for i in range(seq_length):\n",
    "#     if   true_ben[i]: df['d_sc%d' % i] = df['sc_%d' % i] - fB\n",
    "#     elif true_del[i]: df['d_sc%d' % i] = df['sc_%d' % i] - fD\n",
    "\n",
    "\n",
    "# # # AUROC for beneficial and deleterious mutation\n",
    "# # df['AUROC_ben'] = pd.Series(data=[roc_auc_score(true_ben, np.array(df.iloc[i][coefs])) for i in range(len(df))])\n",
    "# # df['AUROC_del'] = pd.Series(data=[roc_auc_score(true_del,-np.array(df.iloc[i][coefs])) for i in range(len(df))])\n",
    "\n",
    "\n",
    "# df.to_csv('%s/mpl_collected_extended.csv'%SIM_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1e623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
