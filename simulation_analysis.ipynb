{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e25a74",
   "metadata": {},
   "source": [
    "# <font color = red> Simulation Analyze\n",
    "This notebook records the parameters for Wright-Fisher simulations used to generate our test data sets, as well as commands for running infernce algorithms on the test data and compiling the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf1a29",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- ### [Libraries and variables](#lib)\n",
    "- ### Data analyze\n",
    "    - [Generation of test data through Wright-Fisher simulations](#sim)\n",
    "    - [Collect multiple simulations](#collect)\n",
    "    - [Finite sample data](#nsdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d18bec",
   "metadata": {},
   "source": [
    "### <a id='lib'></a> Libraries and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "235449e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was prepared using:\n",
      "python version 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:26:08) [Clang 14.0.6 ]\n",
      "numpy version 1.24.2\n",
      "pandas version 1.5.3\n",
      "matplotlib version 3.7.1\n"
     ]
    }
   ],
   "source": [
    "print('This notebook was prepared using:')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "print('python version %s' % sys.version)\n",
    "\n",
    "import numpy as np\n",
    "print('numpy version %s' % np.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "print('pandas version %s' % pd.__version__)\n",
    "\n",
    "import math\n",
    "from math import isnan\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "print('matplotlib version %s' % matplotlib.__version__)\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import scipy as sp\n",
    "import random\n",
    "\n",
    "from scipy import integrate\n",
    "import scipy.interpolate as sp_interpolate\n",
    "import statistics\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import time as time_module\n",
    "\n",
    "import json\n",
    "from importlib import reload\n",
    "\n",
    "import simulation as sim\n",
    "import importlib\n",
    "\n",
    "# GitHub directories\n",
    "HIV_DIR = 'data/HIV'\n",
    "MPL_DIR = 'src/MPL'\n",
    "SIM_DIR = 'data/simulation'\n",
    "FIG_DIR = 'figures'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35f4cd2",
   "metadata": {},
   "source": [
    "<!-- <a id=''></a> -->\n",
    "### Generation of test data through Wright-Fisher simulations\n",
    "The fitness model work like this:\n",
    "$f_a = 1 + \\sum_i^L s_i g_i^a$\n",
    "\n",
    "This simulation begins with 4 random initial type, which only has 2 alleles (wild type and mutant type).\n",
    "\n",
    "Wright-Fisher simulations are performed using simulation.py. The output of these simulations is saved for processing. \n",
    "\n",
    "In this part, we use python code to run mpl.\n",
    "\n",
    "Benefial [0,1], neutral [2,3], delerious[4,5], time varying site (sin(t))[6,7], time varying site (sin(t))[8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f41ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameter\n",
    "importlib.reload(sim)\n",
    "\n",
    "generations = 1000\n",
    "fi_1 = np.zeros(generations+1)\n",
    "fi_2 = np.zeros(generations+1)\n",
    "\n",
    "for t in range(len(fi_1)):\n",
    "    fi_1[t] = np.sin(t*2*np.pi/generations)*0.04\n",
    "    fi_2[t] = np.cos(t*2*np.pi/generations)*0.04\n",
    "    \n",
    "pdata = {  \n",
    "    'NUC':           ['A', 'T'],      # all possible alleles\n",
    "    'dir':           'simple_new',        # directory of this simulation\n",
    "    'xfile':         '0',             # output file name\n",
    "    'output':        '',\n",
    "    'seq_length':    10,              # sequence length\n",
    "    'pop_size':      1000,            # population size\n",
    "    'generations':   generations,     # number of total generations\n",
    "    'totalT':        generations,     # generations used to infer\n",
    "    'mut_rate':      1e-3,            # mutation rate\n",
    "    'rec_rate':      1e-3,            # recombination rate\n",
    "    'inital_state':  4,               # number of initial sub-population\n",
    "    'bene':          [0,1],           # constant beneficial mutations sites\n",
    "    'dele':          [4,5],           # constant deleterious mutations sites\n",
    "    'p_1':           [6,7],           # time-varying mutations sites (sin)\n",
    "    'p_2':           [8,9],           # time-varying mutations sites (cos)\n",
    "    's_ben':         0.02,            # selection coefficient of beneficial mutations\n",
    "    's_del':         -0.02,           # selection coefficient of deleterious mutations\n",
    "    'fi_1':          fi_1,            # time-varying selection coefficient for individual site (sin)\n",
    "    'fi_2':          fi_2,            # time-varying selection coefficient for individual site (cos)\n",
    "    'gamma_s':       1,               # regularization - selection coefficients - constant part\n",
    "    'gamma_2c':      100000,          # regularization - the time derivative of the selection coefficients\n",
    "    'gamma_2tv':     200,             # regularization - the time derivative of the selection coefficients\n",
    "    'bc_n':        True,            # True, using raw data; false, using finite sample noise\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3da6ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done 100 times simulations\n"
     ]
    }
   ],
   "source": [
    "reload(sim)\n",
    "\n",
    "n_sim   = 100\n",
    "\n",
    "# simulation\n",
    "for k in range(n_sim):\n",
    "    pdata['xfile']        = str(k)\n",
    "    sim.simulate_simple(**pdata)\n",
    "\n",
    "print('we have done %d times simulations'%n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3003e2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done inference for 100 simulations \n"
     ]
    }
   ],
   "source": [
    "reload(sim)\n",
    "\n",
    "for n in range(n_sim):\n",
    "    pdata['xfile'] = str(n)\n",
    "    pdata['bc_n']  = True\n",
    "    sim.infer_simple(**pdata)\n",
    "#     pdata['bc_n']  = False\n",
    "#     sim.infer_simple(**pdata)\n",
    "\n",
    "print('we have done inference for %d simulations '%n_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d279a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_dir = pdata['dir']\n",
    "const_num = 6\n",
    "output = '_ls_11'\n",
    "# Neumann boundary condition\n",
    "f = open('%s/%s/mpl_collected%s.csv'%(SIM_DIR,simple_dir,output),'w')\n",
    "f.write('trajectory,ns,delta_t')\n",
    "for i in range(const_num):\n",
    "    f.write(',sc_%d'%i)\n",
    "f.write('\\n')\n",
    "\n",
    "for k in range(n_sim):\n",
    "    name = str(k)\n",
    "    data_full   = np.load('%s/%s/output%s/c_%s.npz'%(SIM_DIR,simple_dir,output,name), allow_pickle=\"True\")\n",
    "    sc_full     = data_full['selection']\n",
    "    TimeVaryingSC = [np.average(sc_full[i]) for i in range(const_num)]\n",
    "    f.write('%d,1000,1'%k)\n",
    "    for i in range(const_num):\n",
    "        f.write(',%f'%TimeVaryingSC[i])\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9de2f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collect all coefficients for 100 simulations\n"
     ]
    }
   ],
   "source": [
    "const_num = 6\n",
    "\n",
    "# Neumann boundary condition\n",
    "f = open('%s/simple/mpl_collected.csv'%(SIM_DIR),'w')\n",
    "f.write('trajectory,ns,delta_t')\n",
    "for i in range(const_num):\n",
    "    f.write(',sc_%d'%i)\n",
    "f.write('\\n')\n",
    "\n",
    "for k in range(n_sim):\n",
    "    name = str(k)\n",
    "    data_full   = np.load('%s/simple/output/c_%s.npz'%(SIM_DIR,name), allow_pickle=\"True\")\n",
    "    sc_full     = data_full['selection']\n",
    "    TimeVaryingSC = [np.average(sc_full[i]) for i in range(const_num)]\n",
    "    f.write('%d,1000,1'%k)\n",
    "    for i in range(const_num):\n",
    "        f.write(',%f'%TimeVaryingSC[i])\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "# # Dirichlet boundary condition\n",
    "# f = open('%s/simple/mpl_collected_d.csv'%(SIM_DIR),'w')\n",
    "# f.write('trajectory,ns,delta_t')\n",
    "# for i in range(const_num):\n",
    "#     f.write(',sc_%d'%i)\n",
    "# f.write('\\n')\n",
    "\n",
    "# for k in range(n_sim):\n",
    "#     name = str(k)\n",
    "#     data_full   = np.load('%s/simple/output_d/c_%s.npz'%(SIM_DIR,name), allow_pickle=\"True\")\n",
    "#     sc_full     = data_full['selection']\n",
    "#     TimeVaryingSC = [np.average(sc_full[i]) for i in range(const_num)]\n",
    "#     f.write('%d,1000,1'%k)\n",
    "#     for i in range(const_num):\n",
    "#         f.write(',%f'%TimeVaryingSC[i])\n",
    "#     f.write('\\n')\n",
    "# f.close()\n",
    "\n",
    "# print('collect all coefficients for %d simulations'%(n_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86a7ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "924df50a",
   "metadata": {},
   "source": [
    "<a id='sim'></a>\n",
    "### Generation of test data through Wright-Fisher simulations\n",
    "The fitness model work like this:\n",
    "$f_a = 1 + \\sum_i^L s_i g_i^a + \\sum_n^{N_p} s_n g_n^a$\n",
    "\n",
    "This simulation begins with 4 random initial type, which only has 2 alleles (wild type and mutant type).\n",
    "\n",
    "Wright-Fisher simulations are performed using simulation.py. The output of these simulations is saved for processing. \n",
    "\n",
    "In this part, we use python code to run mpl.\n",
    "\n",
    "Benefial [0,1,2,3], delerious[16,17,18,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c109fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameter\n",
    "importlib.reload(sim)\n",
    "\n",
    "generations = 1000\n",
    "fn = np.zeros(generations+1)\n",
    "fi = np.zeros(generations+1)\n",
    "\n",
    "for t in range(len(fn)):\n",
    "    fi[t] = 0.04 - 0.08/generations * t\n",
    "    fn[t] = 0.1  - 0.05/generations * t\n",
    "\n",
    "trait_dir = 'trait'\n",
    "pdata = {  \n",
    "    'NUC':           ['A', 'T'],      # all possible alleles\n",
    "    'dir':           trait_dir,       # directory of this simulation\n",
    "    'xfile':         '0',             # output file name\n",
    "    'seq_length':    20,              # sequence length\n",
    "    'pop_size':      1000,            # population size\n",
    "    'generations':   generations,     # number of total generations\n",
    "    'totalT':        generations,     # generations used to infer\n",
    "    'mut_rate':      1e-3,            # mutation rate\n",
    "    'rec_rate':      1e-3,            # recombination rate\n",
    "    'inital_state':  4,               # number of initial sub-population\n",
    "    'n_ben':         4,               # number of beneficial mutations\n",
    "    'n_del':         4,               # number of deleterious mutations\n",
    "    's_ben':         0.02,            # selection coefficient of beneficial mutations\n",
    "    's_del':         -0.02,           # selection coefficient of deleterious mutations\n",
    "    'fi':            fi,              # time-varying selection coefficient for individual site\n",
    "    'fn':            fn,              # time-varying selection coefficient for binary trait\n",
    "    'escape_group':  [[12,15,17]],    # escape sites\n",
    "    'escape_TF':     [[0,0,0]],       # wild type sequences for escape sites\n",
    "    'trait_dis':     [[3,2]],         # distance between trait sites\n",
    "    'p_sites':       [13,18],         # special sites (not escape sites but still time-varying)\n",
    "    'x_thresh':      0.005,           # threshold for single allele frequency\n",
    "    'gamma_s':       1,               # regularization - selection coefficients - constant part\n",
    "    'gamma_2c':      100000,          # regularization - the time derivative of the selection coefficients\n",
    "    'gamma_2tv':     200,             # regularization - the time derivative of the selection coefficients\n",
    "    'bc_n':          True,            # True: Neumann boundary condition; False: Dirichlet boundary condition\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce191131",
   "metadata": {},
   "source": [
    "Use 3 files to restore the information about trait groups. (\"traitsites\": trait sites , \"traitseq\": TF sequences for trait sites,\"traitdis\":distance between 2 neighboring trait sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9b7221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Create the necessary files'\n",
    "reload(sim)\n",
    "\n",
    "n_sim   = 100\n",
    "\n",
    "# # get random escape groups for 100 simulations\n",
    "# escape_groups  = []\n",
    "# special_groups = []\n",
    "# for n in range(n_sim):\n",
    "#     random_numbers   = random.sample(range(20), 5)\n",
    "    \n",
    "#     escape_group_raw = [random_numbers[:3]]\n",
    "#     escape_group     = [sorted(sublist) for sublist in escape_group_raw]\n",
    "#     escape_groups.append(escape_group)\n",
    "    \n",
    "#     p_sites_raw      = [random_numbers[3:]]\n",
    "#     special_group    = [sorted(sublist) for sublist in p_sites_raw]\n",
    "#     special_groups.append(special_group[0])\n",
    "    \n",
    "#     # trait sites \n",
    "#     f = open('%s/%s/traitsite/traitsite-%s.dat'%(SIM_DIR,trait_dir,n), 'w')\n",
    "#     for i in range(len(escape_group)):\n",
    "#         f.write('%s\\n'%'\\t'.join([str(ii) for ii in escape_group[i]]))\n",
    "#     f.close()\n",
    "    \n",
    "#     # distance between 2 trait sites\n",
    "#     f = open('%s/%s/traitdis/traitdis-%s.dat'%(SIM_DIR,trait_dir,n), 'w')\n",
    "#     for i in range(len(escape_group)):\n",
    "#         i_dis = []\n",
    "#         for j in range(len(escape_group[i])-1):\n",
    "#             i_dis.append(int(escape_group[i][j+1]-escape_group[i][j]))\n",
    "#         f.write('%s\\n'%'\\t'.join([str(ii) for ii in i_dis]))\n",
    "#     f.close()\n",
    "    \n",
    "#     # special sites\n",
    "#     f = open('%s/%s/psites/psites-%s.dat'%(SIM_DIR,trait_dir,n), 'w')\n",
    "#     f.write('%s\\n'%'\\t'.join([str(ii) for ii in special_group]))\n",
    "#     f.close()\n",
    "\n",
    "# # trait sequence \n",
    "# f = open('%s/%s/traitseq.dat'%(SIM_DIR,trait_dir), 'w')\n",
    "# for i in range(2):\n",
    "#     f.write('%s\\n'%'\\t'.join([str(0) for j in range(3)]))\n",
    "# f.close()\n",
    "    \n",
    "# # save and load escape group information\n",
    "# with open(\"%s/%s/escape_groups.dat\"%(SIM_DIR,trait_dir), 'w') as file:\n",
    "#     json.dump(escape_groups, file)\n",
    "    \n",
    "# with open(\"%s/%s/special_groups.dat\"%(SIM_DIR,trait_dir), 'w') as file:\n",
    "#     json.dump(special_groups, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "634e8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done 100 times simulations\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sim)\n",
    "\n",
    "with open(\"%s/%s/escape_groups.dat\"%(SIM_DIR,trait_dir), 'r') as file:\n",
    "    escape_groups = json.load(file)\n",
    "\n",
    "with open(\"%s/%s/special_groups.dat\"%(SIM_DIR,trait_dir), 'r') as file:\n",
    "    special_groups = json.load(file)\n",
    "    \n",
    "# simulation\n",
    "for k in range(n_sim):\n",
    "    pdata['xfile']        = str(k)\n",
    "    pdata['escape_group'] = escape_groups[k]\n",
    "    pdata['p_sites']      = special_groups[k]\n",
    "#     sim.simulate_trait(**pdata)\n",
    "\n",
    "print('we have done %d times simulations'%n_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc98a60",
   "metadata": {},
   "source": [
    "Infer the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "323cabf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done inference for 100 simulations \n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sim)\n",
    "\n",
    "for n in range(n_sim):\n",
    "    pdata['xfile']        = str(n)\n",
    "    pdata['p_sites']      = special_groups[n]\n",
    "    sim.infer_trait(**pdata)\n",
    "\n",
    "print('we have done inference for %d simulations '%n_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2a362",
   "metadata": {},
   "source": [
    "#### <a id='collect'></a> Collect multiple simulations\n",
    "Create a csv file to store the results of all simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a99e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nB = pdata['n_ben']\n",
    "nD = pdata['n_del']\n",
    "ne = len(pdata['escape_group'])\n",
    "\n",
    "seq_length = pdata['seq_length']\n",
    "\n",
    "with open(\"%s/%s/special_groups.dat\"%(SIM_DIR,trait_dir), 'r') as file:\n",
    "    special_groups = json.load(file)\n",
    "\n",
    "out_dir = '_ll_12'\n",
    "# Neumann boundary condition\n",
    "f = open('%s/%s/mpl_collecte%s.csv'%(SIM_DIR,trait_dir,out_dir),'w')\n",
    "f.write('trajectory,ns,delta_t')\n",
    "for i in range(seq_length):\n",
    "    f.write(',sc_%d'%i)\n",
    "f.write('\\n')\n",
    "\n",
    "for k in range(100):\n",
    "    name = str(k)\n",
    "    data_full   = np.load('%s/%s/output%s/c_%s.npz'%(SIM_DIR,trait_dir,out_dir,name), allow_pickle=\"True\")\n",
    "    sc_full     = data_full['selection']\n",
    "    TimeVaryingSC = [np.average(sc_full[i]) for i in range(seq_length)]\n",
    "    p_sites = special_groups[k]\n",
    "    f.write('%d,1000,1'%k)\n",
    "    for i in range(seq_length):\n",
    "        if i not in p_sites:\n",
    "            f.write(',%f'%TimeVaryingSC[i])\n",
    "        else:\n",
    "            f.write(',nan')\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f212f471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collect all coefficients for 100 simulations\n"
     ]
    }
   ],
   "source": [
    "nB = pdata['n_ben']\n",
    "nD = pdata['n_del']\n",
    "ne = len(pdata['escape_group'])\n",
    "\n",
    "seq_length = pdata['seq_length']\n",
    "\n",
    "with open(\"%s/%s/special_groups.dat\"%(SIM_DIR,trait_dir), 'r') as file:\n",
    "    special_groups = json.load(file)\n",
    "\n",
    "# Neumann boundary condition\n",
    "f = open('%s/%s/mpl_collected.csv'%(SIM_DIR,trait_dir),'w')\n",
    "f.write('trajectory,ns,delta_t')\n",
    "for i in range(seq_length):\n",
    "    f.write(',sc_%d'%i)\n",
    "f.write('\\n')\n",
    "\n",
    "for k in range(100):\n",
    "    name = str(k)\n",
    "    data_full   = np.load('%s/%s/output/c_%s.npz'%(SIM_DIR,trait_dir,name), allow_pickle=\"True\")\n",
    "    sc_full     = data_full['selection']\n",
    "    TimeVaryingSC = [np.average(sc_full[i]) for i in range(seq_length)]\n",
    "    p_sites = special_groups[k]\n",
    "    f.write('%d,1000,1'%k)\n",
    "    for i in range(seq_length):\n",
    "        if i not in p_sites:\n",
    "            f.write(',%f'%TimeVaryingSC[i])\n",
    "        else:\n",
    "            f.write(',nan')\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "# Dirichlet boundary condition\n",
    "f = open('%s/%s/mpl_collected_d.csv'%(SIM_DIR,trait_dir),'w')\n",
    "f.write('trajectory,ns,delta_t')\n",
    "for i in range(seq_length):\n",
    "    f.write(',sc_%d'%i)\n",
    "f.write('\\n')\n",
    "\n",
    "for k in range(100):\n",
    "    name = str(k)\n",
    "    data_full   = np.load('%s/%s/output_d/c_%s.npz'%(SIM_DIR,trait_dir,name), allow_pickle=\"True\")\n",
    "    sc_full     = data_full['selection']\n",
    "    TimeVaryingSC = [np.average(sc_full[i]) for i in range(seq_length)]\n",
    "    p_sites = special_groups[k]\n",
    "    f.write('%d,1000,1'%k)\n",
    "    for i in range(seq_length):\n",
    "        if i not in p_sites:\n",
    "            f.write(',%f'%TimeVaryingSC[i])\n",
    "        else:\n",
    "            f.write(',nan')\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "print('collect all coefficients for %d simulations'%(k+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0746ed3",
   "metadata": {},
   "source": [
    "#### <a id='nsdt'></a> Finite sample data inference\n",
    "\n",
    "For one simulation, use different n_s and Î”t to get the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffc86a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(sim)\n",
    "\n",
    "ns_vals = [1000, 200, 100, 50, 20, 10]\n",
    "dt_vals = [   1,   5,  10, 20, 50]\n",
    "pdata['ns_vals'] = ns_vals\n",
    "pdata['dt_vals'] = dt_vals\n",
    "\n",
    "for k in range(n_sim):\n",
    "    pdata['xfile'] = str(k)\n",
    "    sim.py2c(**pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dea2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(sim)\n",
    "\n",
    "pdata['IF_raw'] = True\n",
    "pdata['xfile']        = str(0)\n",
    "pdata['p_sites']      = special_groups[0]\n",
    "sim.infer_binary(**pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "538a4472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have done inference for 100 simulations with finite sample\n"
     ]
    }
   ],
   "source": [
    "pdata['IF_raw'] = False\n",
    "for n in range(n_sim):\n",
    "    pdata['p_sites']      = special_groups[n]\n",
    "    for ns in ns_vals:\n",
    "        for dt in dt_vals:\n",
    "            if ns*dt>50:\n",
    "                pdata['xfile'] = str(n)+'_ns'+str(ns)+'_dt'+str(dt)\n",
    "                sim.infer_binary(**pdata)\n",
    "                sim.infer_multiple(**pdata)\n",
    "\n",
    "print('we have done inference for %d simulations with finite sample'%n_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da4d55",
   "metadata": {},
   "source": [
    "collect coefficients for all simulations and write the result into mpl_collected.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b17bf2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collect all coefficients for 100 simulations\n"
     ]
    }
   ],
   "source": [
    "# binary python \n",
    "f = open('%s/mpl_collected_nsdt.csv'%(SIM_DIR),'w')\n",
    "f.write('trajectory,ns,delta_t')\n",
    "for i in range(seq_length):\n",
    "    f.write(',sc_%d'%i)\n",
    "f.write('\\n')\n",
    "\n",
    "for k in range(100):\n",
    "    for ns in ns_vals:\n",
    "        for dt in dt_vals:\n",
    "            if ns*dt>50:\n",
    "                name = str(k)+'_ns'+str(ns)+'_dt'+str(dt)\n",
    "                data_full   = np.load('%s/output/nsdt/c_%s.npz'%(SIM_DIR,name), allow_pickle=\"True\")\n",
    "                sc_full     = data_full['selection']\n",
    "                TimeVaryingSC = [np.average(sc_full[i]) for i in range(seq_length)]\n",
    "                p_sites = special_groups[k]\n",
    "                f.write('%d,%d,%d'%(k,ns,dt))\n",
    "                for i in range(seq_length):\n",
    "                    if i not in p_sites:\n",
    "                        f.write(',%f'%TimeVaryingSC[i])\n",
    "                    else:\n",
    "                        f.write(',nan')\n",
    "                f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "print('collect all coefficients for %d simulations'%(k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3aea77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collect all coefficients for 100 simulations\n"
     ]
    }
   ],
   "source": [
    "# multiple python \n",
    "f = open('%s/mpl_collected_nsdt_multiple.csv'%(SIM_DIR),'w')\n",
    "f.write('trajectory,ns,delta_t')\n",
    "for i in range(seq_length):\n",
    "    f.write(',sc_%d'%i)\n",
    "f.write('\\n')\n",
    "\n",
    "for k in range(100):\n",
    "    for ns in ns_vals:\n",
    "        for dt in dt_vals:\n",
    "            if ns*dt>50:\n",
    "                name = str(k)+'_ns'+str(ns)+'_dt'+str(dt)\n",
    "                data_full   = np.load('%s/output_multiple/nsdt/c_%s.npz'%(SIM_DIR,name), allow_pickle=\"True\")\n",
    "                sc_full     = data_full['selection']\n",
    "                TimeVaryingSC = [np.average((sc_full[2*i+1]-sc_full[2*i])) for i in range(seq_length)]\n",
    "                p_sites = special_groups[k]\n",
    "                f.write('%d,%d,%d'%(k,ns,dt))\n",
    "                for i in range(seq_length):\n",
    "                    if i not in p_sites:\n",
    "                        f.write(',%f'%TimeVaryingSC[i])\n",
    "                    else:\n",
    "                        f.write(',nan')\n",
    "                f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "print('collect all coefficients for %d simulations'%(k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ac0b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "nB = pdata['n_ben']\n",
    "nD = pdata['n_del']\n",
    "\n",
    "fB = pdata['s_ben']\n",
    "fD = pdata['s_del']\n",
    "\n",
    "\n",
    "true_ben = [1 if i in                        range(nB) else 0 for i in range(seq_length)]\n",
    "true_del = [1 if i in range(seq_length-nD, seq_length) else 0 for i in range(seq_length)]\n",
    "\n",
    "coefs = ['sc_%d' % j for j in range(seq_length)]\n",
    "\n",
    "df              = pd.read_csv('%s/mpl_collected_nsdt.csv'%SIM_DIR, memory_map=True)\n",
    "\n",
    "# difference between inferred coefficients and true coefficients\n",
    "for i in range(seq_length):\n",
    "    if   true_ben[i]: df['d_sc%d' % i] = df['sc_%d' % i] - fB\n",
    "    elif true_del[i]: df['d_sc%d' % i] = df['sc_%d' % i] - fD\n",
    "\n",
    "\n",
    "# # AUROC for beneficial and deleterious mutation\n",
    "# df['AUROC_ben'] = pd.Series(data=[roc_auc_score(true_ben, np.array(df.iloc[i][coefs])) for i in range(len(df))])\n",
    "# df['AUROC_del'] = pd.Series(data=[roc_auc_score(true_del,-np.array(df.iloc[i][coefs])) for i in range(len(df))])\n",
    "\n",
    "\n",
    "df.to_csv('%s/mpl_collected_extended.csv'%SIM_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1e623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3287c138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0310898b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0aa30a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMutantS(sVec,nVec):\n",
    "    muVec    = -np.ones(seq_length)\n",
    "    x_length = 0\n",
    "    for i in range(seq_length):\n",
    "        allele_count = np.zeros(len(sVec))\n",
    "        allele_count = [np.sum([(sVec[t][k][i]==1)*nVec[t][k] for k in range(len(sVec[t]))]) for t in range(len(sVec))]\n",
    "        if max(allele_count) / np.sum(nVec[0]) >= 0:\n",
    "            muVec[i] = x_length\n",
    "            x_length += 1\n",
    "    return x_length,muVec\n",
    "\n",
    "def get_allele_frequency(sVec,nVec,eVec,muVec):\n",
    "\n",
    "    x  = np.zeros((len(nVec),x_length))           # single allele frequency\n",
    "    xx = np.zeros((len(nVec),x_length,x_length))  # pair allele frequency\n",
    "    for t in range(len(nVec)):\n",
    "        pop_size_t = np.sum([nVec[t]])\n",
    "        # individual locus part\n",
    "        for i in range(seq_length):\n",
    "            aa = int(muVec[i])\n",
    "            if aa != -1:\n",
    "                x[t,aa] = np.sum([sVec[t][k][i] * nVec[t][k] for k in range(len(sVec[t]))]) / pop_size_t\n",
    "            for j in range(int(i+1), seq_length):\n",
    "                bb = int(muVec[j])\n",
    "                if bb != -1:\n",
    "                    xx[t,aa,bb] = np.sum([sVec[t][k][i] * sVec[t][k][j] * nVec[t][k] for k in range(len(sVec[t]))]) / pop_size_t\n",
    "                    xx[t,aa,bb] = np.sum([sVec[t][k][i] * sVec[t][k][j] * nVec[t][k] for k in range(len(sVec[t]))]) / pop_size_t\n",
    "        # escape part\n",
    "        for n in range(ne):\n",
    "            aa      = x_length-ne+n\n",
    "            x[t,aa] = np.sum([eVec[t][k][n] * nVec[t][k] for k in range(len(sVec[t]))]) / pop_size_t\n",
    "            for m in range(int(n+1), ne):\n",
    "                bb          = x_length-ne+m\n",
    "                xx[t,aa,bb] = np.sum([eVec[t][k][n] * eVec[t][k][m] * nVec[t][k] for k in range(len(sVec[t]))]) / pop_size_t\n",
    "                xx[t,bb,aa] = np.sum([eVec[t][k][n] * eVec[t][k][m] * nVec[t][k] for k in range(len(sVec[t]))]) / pop_size_t\n",
    "            for j in range(seq_length):\n",
    "                bb = int(muVec[j])\n",
    "                if bb != -1:\n",
    "                    xx[t,bb,aa] = np.sum([sVec[t][k][j] * eVec[t][k][n] * nVec[t][k] for k in range(len(sVec[t]))]) / pop_size_t\n",
    "                    xx[t,aa,bb] = np.sum([sVec[t][k][j] * eVec[t][k][n] * nVec[t][k] for k in range(len(sVec[t]))]) / pop_size_t\n",
    "    return x,xx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2dd76462",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Average Covariance\n",
    "# load data\n",
    "data         = np.loadtxt(\"%s/example/example-0.dat\"%(SIM_DIR))\n",
    "seq_length   = 20\n",
    "ne           = 1\n",
    "\n",
    "# Obtain sequence data and frequencies\n",
    "sVec,nVec,eVec = sim.getSequence(data,escape_group)\n",
    "x_length,muVec = getMutantS(sVec,nVec)\n",
    "x_length      += ne\n",
    "\n",
    "# Allele frequencies\n",
    "x,xx         = get_allele_frequency(sVec,nVec,eVec,muVec) \n",
    "\n",
    "# Covariance matrix\n",
    "covariance_n = sim.diffusion_matrix_at_t(x, xx,x_length)\n",
    "covariance   = np.swapaxes(covariance_n, 0, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9e999b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_a = np.zeros((len(covariance),len(covariance[0])))\n",
    "for i in range(len(covariance)):\n",
    "    for j in range(len(covariance[i])):\n",
    "        covariance_a[i,j] = np.average(covariance[i,j,:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "202195ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14262595409181636\n",
      "[0.       0.002991 0.003984 0.004975 0.004975 0.005964 0.005964 0.010879\n",
      " 0.018639 0.021516 0.024375 0.0196   0.016711 0.0196   0.017676 0.0196\n",
      " 0.020559 0.025324 0.0291   0.032844 0.044791 0.050191 0.0384   0.039319\n",
      " 0.0475   0.043884 0.034704 0.035631 0.045696 0.039319 0.042064 0.042975\n",
      " 0.046599 0.059031 0.057279 0.069375 0.075276 0.071071 0.070224 0.071071\n",
      " 0.064239 0.0651   0.072759 0.0651   0.058156 0.054636 0.044791 0.059904\n",
      " 0.052864 0.039319 0.050191 0.0475   0.055519 0.059904 0.064239 0.084351\n",
      " 0.09     0.093184 0.084351 0.086784 0.088396 0.083536 0.085975 0.081079\n",
      " 0.076944 0.088396 0.093184 0.090799 0.108624 0.1131   0.116044 0.113839\n",
      " 0.113839 0.133036 0.144375 0.148876 0.1539   0.158796 0.16     0.154519\n",
      " 0.149511 0.159399 0.156364 0.1716   0.1659   0.162384 0.1716   0.190464\n",
      " 0.198924 0.201159 0.203775 0.207975 0.211975 0.214279 0.220071 0.223104\n",
      " 0.2304   0.226591 0.227199 0.227799 0.230956 0.226591 0.235359 0.240784\n",
      " 0.240975 0.245644 0.244524 0.242256 0.241719 0.244224 0.244375 0.246636\n",
      " 0.245239 0.246636 0.244959 0.246279 0.244375 0.247084 0.248556 0.247884\n",
      " 0.248704 0.248775 0.248319 0.248704 0.248976 0.249324 0.249216 0.249639\n",
      " 0.2496   0.249831 0.246975 0.246156 0.246751 0.247296 0.248631 0.2484\n",
      " 0.244816 0.247399 0.248775 0.247399 0.246975 0.245904 0.247296 0.248151\n",
      " 0.2475   0.249039 0.249775 0.249711 0.249991 0.249831 0.249424 0.249775\n",
      " 0.249999 0.249964 0.249964 0.249879 0.249639 0.247296 0.245511 0.243759\n",
      " 0.242431 0.245239 0.241536 0.239391 0.238119 0.235839 0.238336 0.239596\n",
      " 0.240591 0.238764 0.236076 0.235359 0.238119 0.236544 0.242079 0.241719\n",
      " 0.244224 0.241164 0.244524 0.240975 0.244224 0.245904 0.246864 0.247296\n",
      " 0.249324 0.2499   0.249216 0.247975 0.244959 0.239799 0.240396 0.239799\n",
      " 0.238975 0.240591 0.244816 0.243111 0.240396 0.242256 0.243439 0.245511\n",
      " 0.2436   0.244524 0.245644 0.240396 0.24     0.240396 0.2379   0.237456\n",
      " 0.234871 0.230679 0.2304   0.230956 0.225975 0.225975 0.219024 0.213519\n",
      " 0.216511 0.220071 0.226284 0.226284 0.222111 0.228684 0.228684 0.231231\n",
      " 0.231504 0.225975 0.230956 0.232044 0.230956 0.223756 0.221776 0.228684\n",
      " 0.230119 0.221776 0.208791 0.214279 0.219024 0.215775 0.217959 0.213136\n",
      " 0.208384 0.210399 0.217239 0.215031 0.214656 0.200271 0.199375 0.203344\n",
      " 0.1924   0.194775 0.200716 0.2016   0.204631 0.203775 0.214279 0.215775\n",
      " 0.2176   0.228975 0.2304   0.2356   0.231775 0.234375 0.2304   0.225351\n",
      " 0.232044 0.236311 0.234375 0.237004 0.2331   0.224079 0.222444 0.224719\n",
      " 0.224719 0.214656 0.210796 0.214656 0.218316 0.212364 0.216144 0.213136\n",
      " 0.220071 0.216144 0.213136 0.221776 0.216876 0.213519 0.2016   0.205056\n",
      " 0.199824 0.205479 0.195711 0.189975 0.183951 0.184464 0.186999 0.172716\n",
      " 0.187999 0.184975 0.1716   0.183951 0.180304 0.173271 0.177639 0.171039\n",
      " 0.164736 0.161196 0.165319 0.165319 0.154519 0.146959 0.144375 0.149511\n",
      " 0.157584 0.162384 0.162975 0.158796 0.155136 0.146316 0.142416 0.148876\n",
      " 0.1476   0.150775 0.165319 0.179775 0.174375 0.184464 0.195244 0.189975\n",
      " 0.176016 0.164736 0.161196 0.1539   0.151404 0.142416 0.152656 0.144375\n",
      " 0.143724 0.135756 0.133036 0.123975 0.101775 0.092391 0.089199 0.079431\n",
      " 0.088396 0.071071 0.076944 0.065959 0.071916 0.076111 0.064239 0.076944\n",
      " 0.082719 0.080256 0.064239 0.059904 0.067671 0.083536 0.083536 0.084351\n",
      " 0.084351 0.085164 0.087591 0.079431 0.0564   0.048399 0.054636 0.050191\n",
      " 0.058156 0.067671 0.077775 0.071916 0.080256 0.09     0.094764 0.087591\n",
      " 0.079431 0.066816 0.062511 0.064239 0.071071 0.076944 0.071071 0.076944\n",
      " 0.080256 0.085975 0.083536 0.089199 0.088396 0.088396 0.090799 0.102544\n",
      " 0.104076 0.101775 0.093975 0.088396 0.070224 0.071071 0.075276 0.081079\n",
      " 0.085975 0.0979   0.076944 0.0819   0.071071 0.059904 0.053751 0.048399\n",
      " 0.053751 0.050191 0.045696 0.040236 0.042064 0.0384   0.037479 0.0384\n",
      " 0.036556 0.030976 0.032844 0.035631 0.033775 0.0291   0.033775 0.031911\n",
      " 0.033775 0.030039 0.035631 0.049296 0.046599 0.042975 0.041151 0.045696\n",
      " 0.042064 0.049296 0.050191 0.049296 0.043884 0.0475   0.052864 0.051084\n",
      " 0.053751 0.0564   0.076944 0.066816 0.065959 0.072759 0.060775 0.051975\n",
      " 0.045696 0.041151 0.042064 0.042975 0.030976 0.040236 0.049296 0.043884\n",
      " 0.041151 0.035631 0.039319 0.033775 0.041151 0.045696 0.048399 0.043884\n",
      " 0.041151 0.0384   0.039319 0.041151 0.034704 0.033775 0.031911 0.033775\n",
      " 0.045696 0.053751 0.057279 0.062511 0.062511 0.051975 0.058156 0.067671\n",
      " 0.069375 0.060775 0.063376 0.069375 0.066816 0.070224 0.068524 0.068524\n",
      " 0.069375 0.070224 0.076111 0.072759 0.0736   0.076944 0.069375 0.068524\n",
      " 0.071916 0.079431 0.077775 0.075276 0.069375]\n"
     ]
    }
   ],
   "source": [
    "print(covariance_a[0,0])\n",
    "print(covariance[0,0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd675843",
   "metadata": {},
   "outputs": [],
   "source": [
    "### orthogonal diagonalization\n",
    "\n",
    "import scipy.linalg as la\n",
    "\n",
    "\n",
    "A1 = np.array([[2, -1], [1, 3]])\n",
    "b1 = np.array([1, 0])\n",
    "A2 = np.array([[1, 2], [-1, 4]])\n",
    "b2 = np.array([0, 1])\n",
    "\n",
    "\n",
    "u_prime_0 = 1\n",
    "u_prime_1 = 2\n",
    "\n",
    "\n",
    "t_start = 0\n",
    "t_end = 1\n",
    "num_intervals = 100\n",
    "dt = (t_end - t_start) / num_intervals\n",
    "t_half = int(num_intervals / 2)\n",
    "\n",
    "\n",
    "def orthogonal_diagonalization(A):\n",
    "    eigvals, eigvecs = la.eig(A)\n",
    "    Q = eigvecs\n",
    "    D = np.diag(eigvals)\n",
    "    return Q, D\n",
    "\n",
    "Q1, D1 = orthogonal_diagonalization(A1)\n",
    "Q2, D2 = orthogonal_diagonalization(A2)\n",
    "\n",
    "\n",
    "b1_transformed = Q1.T @ b1\n",
    "b2_transformed = Q2.T @ b2\n",
    "\n",
    "\n",
    "def finite_difference_method(D, b_transformed, dt, num_intervals, initial_condition):\n",
    "    x = np.zeros((D.shape[0], num_intervals + 1))\n",
    "    x[:, 0] = initial_condition\n",
    "    for i in range(num_intervals):\n",
    "        x[:, i + 1] = x[:, i] + dt * (D @ x[:, i] + b_transformed)\n",
    "    return x\n",
    "\n",
    "\n",
    "x1 = finite_difference_method(D1, b1_transformed, dt, t_half, np.array([0, 0]))\n",
    "x2_initial_condition = Q1 @ x1[:, t_half] - Q2 @ x1[:, t_half] + (u_prime_0 * dt) * np.array([1, 0])\n",
    "x2 = finite_difference_method(D2, b2_transformed, dt, t_half, x2_initial_condition)\n",
    "\n",
    "\n",
    "u1 = Q1 @ x1\n",
    "u2 = Q2 @ x2\n",
    "\n",
    "\n",
    "u = np.hstack((u1[:, :t_half], u2[:, 1:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb42d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9ef3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a75de2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sim)\n",
    "\n",
    "# inference\n",
    "pdata['xpath']    = 'jobs'\n",
    "for n in range(n_sim):\n",
    "    pdata['xfile'] = str(n)\n",
    "    sim.infer_binary(**pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7488e59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.016443938397976306, 0.01839057910090518, 0.016954357072892424, 0.007952794805819752, -0.00010838909471058121, -0.0026846497716975664, -0.004497659231641359, -0.0017100268149185499, -0.0011023367612964941, 0.0030902011440607784, -0.004467527252911888, -0.0012500813284500273, 0.0026862670416833655, 0.0011594286845331102, -0.005469852620909327, -0.006463447223312858, -0.011758975207705382, -0.01230974345262893, -0.01610816459542871, -0.013210852761702311]\n",
      "[0.01641512 0.0164152  0.01641528 0.01641535 0.01641541 0.01641546\n",
      " 0.0164155  0.01641556 0.01641563 0.01641568]\n",
      "[0.02032294086114561, 0.023286064722280557, 0.020527547093306203, 0.009924747185991682, -0.0019360454401982218, -0.0029482882722519344, -0.005155539471279753, -0.0025383234078301333, -0.0010977250380106993, 0.003161800079556894, -0.005034400960466398, -0.0020927823901811284, 0.0023538538704306056, 0.0011164760936466826, -0.005916639688167631, -0.008831599304957, -0.015112407528142737, -0.016692912960450574, -0.02098863002360293, -0.01854336344332321]\n",
      "[0.02027926 0.02027936 0.02027947 0.02027954 0.02027959 0.02027963\n",
      " 0.02027965 0.0202797  0.02027977 0.02027982]\n"
     ]
    }
   ],
   "source": [
    "name = 'example'\n",
    "seq_length = 20\n",
    "\n",
    "\n",
    "data_full   = np.load('%s/example/c_%s_new.npz'%(SIM_DIR,name), allow_pickle=\"True\")\n",
    "sc_full     = data_full['selection']\n",
    "TimeVaryingSC = [np.average(sc_full[i]) for i in range(seq_length)]\n",
    "print(TimeVaryingSC)\n",
    "print(sc_full[0][:10])\n",
    "\n",
    "data_full   = np.load('%s/example/c_%s_multiple.npz'%(SIM_DIR,name), allow_pickle=\"True\")\n",
    "sc_full     = data_full['selection']\n",
    "TimeVaryingSC = [np.average(sc_full[2*i+1]-sc_full[2*i]) for i in range(seq_length)]\n",
    "# TimeVaryingSC = [np.average(TimeVaryingSC[i]) for i in range(seq_length)]\n",
    "print(TimeVaryingSC)\n",
    "print(sc_full[1][:10]-sc_full[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e92b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############################## Function ####################################\n",
    "def getSequence(history,escape_group):\n",
    "    sVec      = []\n",
    "    nVec      = []\n",
    "    eVec      = []\n",
    "\n",
    "    temp_sVec   = []\n",
    "    temp_nVec   = []\n",
    "    temp_eVec   = []\n",
    "\n",
    "    times       = []\n",
    "    time        = 0\n",
    "    times.append(time)\n",
    "\n",
    "    ne          = len(escape_group)\n",
    "\n",
    "    for t in range(len(history)):\n",
    "        if history[t][0] != time:\n",
    "            time = history[t][0]\n",
    "            times.append(int(time))\n",
    "            sVec.append(temp_sVec)\n",
    "            nVec.append(temp_nVec)\n",
    "            eVec.append(temp_eVec)\n",
    "            temp_sVec   = []\n",
    "            temp_nVec   = []\n",
    "            temp_eVec   = []\n",
    "\n",
    "        temp_nVec.append(history[t][1])\n",
    "        temp_sVec.append(history[t][2:])\n",
    "\n",
    "        if ne > 0: # the patient contains escape group\n",
    "            temp_escape = np.zeros(ne, dtype=int)\n",
    "            for n in range(ne):\n",
    "                for nn in range(len(escape_group[n])):\n",
    "                    index = escape_group[n][nn] + 2\n",
    "                    if history[t][index] != 0:\n",
    "                        temp_escape[n] = 1\n",
    "                        break\n",
    "            temp_eVec.append(temp_escape)\n",
    "\n",
    "        if t == len(history)-1:\n",
    "            sVec.append(temp_sVec)\n",
    "            nVec.append(temp_nVec)\n",
    "            eVec.append(temp_eVec)\n",
    "\n",
    "    return sVec,nVec,eVec\n",
    "\n",
    "def getMutantS(sVec,nVec):\n",
    "    # use muVec matrix to record the index of time-varying sites(after throwing out weak linkage sites)\n",
    "    muVec = -np.ones((seq_length, q)) # default value is -1, positive number means the index\n",
    "    x_length  = 0\n",
    "    for i in range(seq_length):\n",
    "        allele_uniq = [int(j) for j in np.unique(sVec[:][:][i])] # all possible alleles in site i\n",
    "        for allele in allele_uniq:\n",
    "            # throw out the alleles with low frequency\n",
    "            allele_count = np.zeros(len(sVec))\n",
    "            allele_count = [np.sum([(sVec[t][k][i]==allele)*nVec[t][k] for k in range(len(sVec[t]))]) for t in range(len(sVec))]\n",
    "            if max(allele_count) / np.sum(nVec[0]) >= x_thresh:\n",
    "                muVec[i][int(allele)] = x_length\n",
    "                x_length += 1\n",
    "    return x_length,muVec\n",
    "\n",
    "############################################################################\n",
    "####################### Inference (binary case) ############################\n",
    "# obtain raw data\n",
    "data         = np.loadtxt(\"%s/example/example.dat\"%(SIM_DIR))\n",
    "escape_group = [[12,15,17]]\n",
    "ne           = len(escape_group)\n",
    "\n",
    "# obtain sequence data and frequencies\n",
    "sVec,nVec,eVec = getSequence(data,escape_group)\n",
    "x_length,muVec = getMutantS(sVec,nVec)\n",
    "x_length += ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc12c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.5478200912475586 seconds\n",
      "[ 750.  250. 1000.    0.  750.  250.  750.  250. 1000.    0.  750.  250.\n",
      "  500.  500.  750.  250.  750.  250.  750.  250.  750.  250.  750.  250.\n",
      " 1000.    0.  750.  250. 1000.    0.  750.  250.  500.  500. 1000.    0.\n",
      "  500.  500. 1000.    0.    0.]\n",
      "Execution time: 1.6201841831207275 seconds\n",
      "[ 750.  250. 1000.    0.  750.  250.  750.  250. 1000.    0.  750.  250.\n",
      "  500.  500.  750.  250.  750.  250.  750.  250.  750.  250.  750.  250.\n",
      " 1000.    0.  750.  250. 1000.    0.  750.  250.  500.  500. 1000.    0.\n",
      "  500.  500. 1000.    0.    0.]\n"
     ]
    }
   ],
   "source": [
    "import time as time_module\n",
    "q = 2\n",
    "x_thresh = 0.01\n",
    "x = np.zeros((len(nVec),x_length))  # pair allele frequency\n",
    "xx = np.zeros((len(nVec),x_length,x_length))  # pair allele frequency\n",
    "\n",
    "start_time = time_module.time()\n",
    "'''code 1'''\n",
    "\n",
    "'''code 1'''\n",
    "end_time = time_module.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "start_time = time_module.time()\n",
    "'''code 2'''\n",
    "\n",
    "'''code 2'''\n",
    "end_time = time_module.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8645d7",
   "metadata": {},
   "source": [
    "### Dealing with the output\n",
    "collect coefficients for all simulations and write the result into mpl_collected.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99123e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collect all coefficients for 100 simulations\n"
     ]
    }
   ],
   "source": [
    "nB = pdata['n_ben']\n",
    "nD = pdata['n_del']\n",
    "ne = len(pdata['escape_group'])\n",
    "p_sites = pdata['p_sites']\n",
    "seq_length = pdata['seq_length']\n",
    "dirr = '2n1d-10-500'\n",
    "\n",
    "f = open('%s/mpl_collected_%s.csv'%(SIM_DIR,dirr),'w')\n",
    "f.write('trajectory')\n",
    "for i in range(seq_length):\n",
    "    if i not in p_sites:\n",
    "        f.write(',sc_%d'%i)\n",
    "f.write('\\n')\n",
    "\n",
    "for k in range(100):\n",
    "    name = 'example-2n1d-'+str(k)\n",
    "    data_full   = np.load('%s/%s/c_%s.npz'%(SIM_DIR,dirr,name), allow_pickle=\"True\")\n",
    "    sc_full     = data_full['selection']\n",
    "    TimeVaryingSC = [np.average((sc_full[2*i+1]-sc_full[2*i])) for i in range(seq_length)]\n",
    "    f.write('%d'%k)\n",
    "    for i in range(seq_length):\n",
    "        if i not in p_sites:\n",
    "            f.write(',%f'%TimeVaryingSC[i])\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "print('collect all coefficients for %d simulations'%(k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8264ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    name = 'example-2n1d-'+str(i)\n",
    "    sc = np.loadtxt('%s/2n1d/sc-%s-const.dat'%(SIM_DIR,name))\n",
    "    if len(sc) != 21:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aeafecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "reload(sim)\n",
    "\n",
    "'''1N2D'''\n",
    "\n",
    "generations = 500\n",
    "fP = np.zeros(generations+1)\n",
    "for t in range(len(fP)):\n",
    "    fP[t] = 0.05 - 0.05/generations * t\n",
    "\n",
    "pdata = {  \n",
    "    'NUC':           ['A', 'C'],      # all possible alleles                              \n",
    "    'name':          'example',       # output file name\n",
    "    'seq_length':    20,              # sequence length\n",
    "    'pop_size':      1000,            # population size\n",
    "    'generations':   generations,     # number of total generations\n",
    "    'totalT':        500,             # generations used to infer\n",
    "    'mutation_rate': 1e-3,            # mutation rate\n",
    "    'inital_state':  4,               # number of initial sub-population\n",
    "    'n_ben':         4,               # number of beneficial mutations\n",
    "    'n_del':         4,               # number of deleterious mutations\n",
    "    's_ben':         0.02,            # selection coefficient of beneficial mutations\n",
    "    's_del':         -0.02,           # selection coefficient of deleterious mutations\n",
    "    'fP':            fP,              # time-varying selection coefficient\n",
    "    'escape_group':  [[12,16,19]],      # escape sites\n",
    "    'p_sites':       [13,18],         # special sites (not escape sites but still time-varying)\n",
    "    'x_thresh':      0.001,           # threshold for single allele frequency\n",
    "    'gamma_s':       10,              # regularization - selection coefficients - constant part\n",
    "    'gamma_2c':      1000000,         # regularization - the time derivative of the selection coefficients\n",
    "    'gamma_2tv':     200,             # regularization - the time derivative of the selection coefficients\n",
    "    }\n",
    "\n",
    "for i in range(100):\n",
    "    pdata['name'] = 'example-1n2d-'+str(i)\n",
    "    sim.simulate(**pdata)\n",
    "    sim.infer_const(**pdata)\n",
    "    sim.infer_binary(**pdata)\n",
    "    sim.infer_multiple(**pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3a1f9fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collect all coefficients for 100 simulations\n"
     ]
    }
   ],
   "source": [
    "nB = pdata['n_ben']\n",
    "nD = pdata['n_del']\n",
    "ne = len(pdata['escape_group'])\n",
    "p_sites = pdata['p_sites']\n",
    "seq_length = pdata['seq_length']\n",
    "\n",
    "f = open('%s/mpl_collected_1n2d.csv'%SIM_DIR,'w')\n",
    "f.write('trajectory')\n",
    "for i in range(seq_length):\n",
    "    if i not in p_sites:\n",
    "        f.write(',sc_%d'%i)\n",
    "f.write('\\n')\n",
    "\n",
    "for k in range(100):\n",
    "    name = 'example-1n2d-'+str(k)\n",
    "    data_full   = np.load('%s/1n2d/c_%s.npz'%(SIM_DIR,name), allow_pickle=\"True\")\n",
    "    sc_full     = data_full['selection']\n",
    "    TimeVaryingSC = [np.average((sc_full[2*i+1]-sc_full[2*i])) for i in range(seq_length)]\n",
    "    f.write('%d'%k)\n",
    "    for i in range(seq_length):\n",
    "        if i not in p_sites:\n",
    "            f.write(',%f'%TimeVaryingSC[i])\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "print('collect all coefficients for %d simulations'%(k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b71cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
